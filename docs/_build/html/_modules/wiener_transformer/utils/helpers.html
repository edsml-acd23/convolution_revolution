<!DOCTYPE html>

<html lang="en" data-content_root="../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>wiener_transformer.utils.helpers &#8212; Wiener Transformer 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../_static/basic.css?v=c058f7c8" />
    <link rel="stylesheet" type="text/css" href="../../../_static/alabaster.css?v=27fed22d" />
    <script src="../../../_static/documentation_options.js?v=f2a433a1"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
   
  <link rel="stylesheet" href="../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for wiener_transformer.utils.helpers</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">contextlib</span> <span class="kn">import</span> <span class="n">nullcontext</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nltk</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">nltk.translate.bleu_score</span> <span class="kn">import</span> <span class="n">sentence_bleu</span><span class="p">,</span> <span class="n">corpus_bleu</span><span class="p">,</span> <span class="n">SmoothingFunction</span>
<span class="kn">from</span> <span class="nn">sacrebleu.metrics</span> <span class="kn">import</span> <span class="n">BLEU</span>
<span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>


<div class="viewcode-block" id="calculate_bleu">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.calculate_bleu">[docs]</a>
<span class="k">def</span> <span class="nf">calculate_bleu</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_dataloader</span><span class="p">,</span> <span class="n">pad_idx</span><span class="p">,</span> <span class="n">tgt_tokenizer</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">50</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Calculate BLEU scores and BERTScore for model predictions on the test dataset.</span>

<span class="sd">    Args:</span>
<span class="sd">        model: The trained model to be evaluated.</span>
<span class="sd">        test_dataloader: DataLoader providing batches of test data.</span>
<span class="sd">        pad_idx: The index used for padding in the sequences.</span>
<span class="sd">        tgt_tokenizer: Tokenizer for the target language.</span>
<span class="sd">        max_len: Maximum length for generated sequences (default: 50).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing:</span>
<span class="sd">            - corpus_bleu_score: BLEU score for the entire corpus.</span>
<span class="sd">            - average_sentence_bleu_score: Average BLEU score for individual sentences.</span>
<span class="sd">            - sacrebleu_score: SacreBLEU score for the corpus.</span>
<span class="sd">            - recall: Average BERTScore recall.</span>
<span class="sd">            - precision: Average BERTScore precision.</span>
<span class="sd">            - f1: Average BERTScore F1 score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">loggers</span> <span class="o">=</span> <span class="p">[</span><span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">logging</span><span class="o">.</span><span class="n">root</span><span class="o">.</span><span class="n">manager</span><span class="o">.</span><span class="n">loggerDict</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">logger</span> <span class="ow">in</span> <span class="n">loggers</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;transformers&quot;</span> <span class="ow">in</span> <span class="n">logger</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">lower</span><span class="p">():</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">ERROR</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <span class="n">all_references</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_hypotheses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_references_untokenized</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">all_hypotheses_untokenized</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">total_sentence_bleu</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">num_sentences</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">smoothing_function</span> <span class="o">=</span> <span class="n">SmoothingFunction</span><span class="p">()</span><span class="o">.</span><span class="n">method1</span>

    <span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s2">&quot;punkt&quot;</span><span class="p">,</span> <span class="n">download_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_dir&quot;</span><span class="p">,</span> <span class="s2">&quot;/scratch_brain/acd23/code/irp-acd23&quot;</span><span class="p">))</span>
    <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_dir&quot;</span><span class="p">,</span> <span class="s2">&quot;/scratch_brain/acd23/code/irp-acd23&quot;</span><span class="p">))</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">):</span>
            <span class="n">src_sentences</span><span class="p">,</span> <span class="n">tgt_sentences</span> <span class="o">=</span> <span class="n">batch</span>
            
            <span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src_sentences</span> <span class="o">!=</span> <span class="n">pad_idx</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">src_sentences</span> <span class="o">=</span> <span class="n">src_sentences</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            <span class="n">src_mask</span> <span class="o">=</span> <span class="n">src_mask</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
            
            <span class="n">memory</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">src_sentences</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">)</span>
            
            <span class="n">start_token</span> <span class="o">=</span> <span class="n">tgt_tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p">(</span><span class="s2">&quot;&lt;s&gt;&quot;</span><span class="p">)</span>
            <span class="n">end_token</span> <span class="o">=</span> <span class="n">tgt_tokenizer</span><span class="o">.</span><span class="n">token_to_id</span><span class="p">(</span><span class="s2">&quot;&lt;/s&gt;&quot;</span><span class="p">)</span>
            <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">src_sentences</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="n">start_token</span><span class="p">)</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span><span class="n">src_sentences</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_len</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
                <span class="n">tgt_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">ys</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)),</span> <span class="n">device</span><span class="o">=</span><span class="n">ys</span><span class="o">.</span><span class="n">device</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                
                <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">memory</span><span class="p">,</span> <span class="n">src_mask</span><span class="p">,</span> <span class="n">ys</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="p">)</span>
                
                <span class="n">prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generator</span><span class="p">(</span><span class="n">out</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">_</span><span class="p">,</span> <span class="n">next_word</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">prob</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">next_word</span> <span class="o">=</span> <span class="n">next_word</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
                
                <span class="n">ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ys</span><span class="p">,</span> <span class="n">next_word</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

            <span class="n">trimmed_ys</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">ys</span><span class="p">:</span>
                <span class="n">trimmed_seq</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">seq</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">end_token</span><span class="p">:</span>
                        <span class="k">break</span>
                    <span class="n">trimmed_seq</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
                <span class="n">trimmed_ys</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trimmed_seq</span><span class="p">)</span>

            <span class="n">hypotheses</span> <span class="o">=</span> <span class="p">[</span><span class="n">tgt_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">trimmed_ys</span><span class="p">]</span>
            <span class="n">tgt_sentences_str</span> <span class="o">=</span> <span class="p">[</span><span class="n">tgt_tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">tgt_sentence</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">for</span> <span class="n">tgt_sentence</span> <span class="ow">in</span> <span class="n">tgt_sentences</span><span class="p">]</span>

            <span class="k">for</span> <span class="n">hypothesis</span><span class="p">,</span> <span class="n">tgt_sentence_str</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hypotheses</span><span class="p">,</span> <span class="n">tgt_sentences_str</span><span class="p">):</span>
                <span class="n">hypothesis</span> <span class="o">=</span> <span class="n">hypothesis</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">tgt_sentence_str</span> <span class="o">=</span> <span class="n">tgt_sentence_str</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
                <span class="n">all_hypotheses_untokenized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hypothesis</span><span class="p">)</span>
                <span class="n">all_references_untokenized</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tgt_sentence_str</span><span class="p">)</span>
                <span class="n">reference_tokens</span> <span class="o">=</span> <span class="n">tgt_sentence_str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
                <span class="n">hypothesis_tokens</span> <span class="o">=</span> <span class="n">hypothesis</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>

                <span class="k">if</span> <span class="n">hypothesis_tokens</span> <span class="ow">and</span> <span class="n">reference_tokens</span><span class="p">:</span>
                    <span class="n">all_hypotheses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hypothesis_tokens</span><span class="p">)</span>
                    <span class="n">all_references</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">reference_tokens</span><span class="p">])</span>

                    <span class="n">sentence_bleu_score</span> <span class="o">=</span> <span class="n">sentence_bleu</span><span class="p">([</span><span class="n">reference_tokens</span><span class="p">],</span> <span class="n">hypothesis_tokens</span><span class="p">,</span> <span class="n">smoothing_function</span><span class="o">=</span><span class="n">smoothing_function</span><span class="p">)</span>
                    <span class="n">total_sentence_bleu</span> <span class="o">+=</span> <span class="n">sentence_bleu_score</span>
                    <span class="n">num_sentences</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">corpus_bleu_score</span> <span class="o">=</span> <span class="n">corpus_bleu</span><span class="p">(</span><span class="n">all_references</span><span class="p">,</span> <span class="n">all_hypotheses</span><span class="p">,</span> <span class="n">smoothing_function</span><span class="o">=</span><span class="n">smoothing_function</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
    <span class="n">average_sentence_bleu_score</span> <span class="o">=</span> <span class="p">(</span><span class="n">total_sentence_bleu</span> <span class="o">/</span> <span class="n">num_sentences</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span> <span class="k">if</span> <span class="n">num_sentences</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="n">sacre_bleu</span> <span class="o">=</span> <span class="n">BLEU</span><span class="p">()</span>
    <span class="n">sacrebleu_score</span> <span class="o">=</span> <span class="n">sacre_bleu</span><span class="o">.</span><span class="n">corpus_score</span><span class="p">(</span><span class="n">all_hypotheses_untokenized</span><span class="p">,</span> <span class="p">[</span><span class="n">all_references_untokenized</span><span class="p">])</span><span class="o">.</span><span class="n">score</span>

    <span class="n">bertscore</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;bertscore&quot;</span><span class="p">,</span> <span class="n">cache_dir</span><span class="o">=</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;base_dir&quot;</span><span class="p">,</span> <span class="s2">&quot;/scratch_brain/acd23&quot;</span><span class="p">))</span>
    <span class="n">results</span> <span class="o">=</span> <span class="n">bertscore</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">all_hypotheses_untokenized</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">all_references_untokenized</span><span class="p">,</span> <span class="n">lang</span><span class="o">=</span><span class="s2">&quot;de&quot;</span><span class="p">)</span>
    <span class="n">recall</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;recall&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">precision</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">f1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">results</span><span class="p">[</span><span class="s2">&quot;f1&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">corpus_bleu_score</span><span class="p">,</span> <span class="n">average_sentence_bleu_score</span><span class="p">,</span> <span class="n">sacrebleu_score</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">precision</span><span class="p">,</span> <span class="n">f1</span></div>



<div class="viewcode-block" id="TrainState">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.TrainState">[docs]</a>
<span class="k">class</span> <span class="nc">TrainState</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Track the number of steps, examples, and tokens processed during training.</span>

<span class="sd">    Attributes:</span>
<span class="sd">        step (int): Number of steps in the current epoch.</span>
<span class="sd">        accum_step (int): Number of gradient accumulation steps.</span>
<span class="sd">        samples (int): Total number of examples used.</span>
<span class="sd">        tokens (int): Total number of tokens processed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Steps in the current epoch</span>
    <span class="n">accum_step</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Number of gradient accumulation steps</span>
    <span class="n">samples</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># total # of examples used</span>
    <span class="n">tokens</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># total # of tokens processed</span></div>



<div class="viewcode-block" id="Batch">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.Batch">[docs]</a>
<span class="k">class</span> <span class="nc">Batch</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Object for holding a batch of data with masks during training.</span>

<span class="sd">    Args:</span>
<span class="sd">        src: Source sequences for the batch.</span>
<span class="sd">        tgt: Target sequences for the batch (default: None).</span>
<span class="sd">        pad: Index used for padding (default: 2).</span>

<span class="sd">    Attributes:</span>
<span class="sd">        src: Source sequences for the batch.</span>
<span class="sd">        src_mask: Mask indicating non-padding elements in the source sequences.</span>
<span class="sd">        tgt: Target sequences without the last token (teacher forcing).</span>
<span class="sd">        tgt_y: Target sequences without the first token (teacher forcing).</span>
<span class="sd">        tgt_mask: Mask indicating non-padding elements and future positions in the target sequences.</span>
<span class="sd">        ntokens: Total number of non-padding tokens in the target sequences.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pad</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>  <span class="c1"># 2 = &lt;blank&gt;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src</span> <span class="o">=</span> <span class="n">src</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">src</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">tgt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tgt</span> <span class="o">=</span> <span class="n">tgt</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tgt_y</span> <span class="o">=</span> <span class="n">tgt</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tgt_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">make_std_mask</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tgt</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">ntokens</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tgt_y</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">)</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<div class="viewcode-block" id="Batch.make_std_mask">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.Batch.make_std_mask">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">make_std_mask</span><span class="p">(</span><span class="n">tgt</span><span class="p">,</span> <span class="n">pad</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a mask to hide padding and future words in the target sequences.</span>

<span class="sd">        Args:</span>
<span class="sd">            tgt: Target sequences.</span>
<span class="sd">            pad: Index used for padding.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tensor representing the mask for the target sequences.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">tgt</span> <span class="o">!=</span> <span class="n">pad</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">tgt_mask</span> <span class="o">=</span> <span class="n">tgt_mask</span> <span class="o">&amp;</span> <span class="n">subsequent_mask</span><span class="p">(</span><span class="n">tgt</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">type_as</span><span class="p">(</span>
            <span class="n">tgt_mask</span><span class="o">.</span><span class="n">data</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">tgt_mask</span></div>
</div>

    

<div class="viewcode-block" id="DummyOptimizer">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.DummyOptimizer">[docs]</a>
<span class="k">class</span> <span class="nc">DummyOptimizer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A dummy optimizer that does nothing. Used for testing or evaluation without updates.</span>

<span class="sd">    Methods:</span>
<span class="sd">        step(): Placeholder method to simulate an optimizer step.</span>
<span class="sd">        zero_grad(set_to_none=False): Placeholder method to simulate zeroing gradients.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_groups</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}]</span>
        <span class="kc">None</span>

<div class="viewcode-block" id="DummyOptimizer.step">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.DummyOptimizer.step">[docs]</a>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kc">None</span></div>


<div class="viewcode-block" id="DummyOptimizer.zero_grad">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.DummyOptimizer.zero_grad">[docs]</a>
    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">set_to_none</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="kc">None</span></div>
</div>



<div class="viewcode-block" id="DummyScheduler">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.DummyScheduler">[docs]</a>
<span class="k">class</span> <span class="nc">DummyScheduler</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A dummy learning rate scheduler that does nothing. Used for testing or evaluation without updates.</span>

<span class="sd">    Methods:</span>
<span class="sd">        step(): Placeholder method to simulate a scheduler step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
<div class="viewcode-block" id="DummyScheduler.step">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.DummyScheduler.step">[docs]</a>
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kc">None</span></div>
</div>

    

<div class="viewcode-block" id="subsequent_mask">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.subsequent_mask">[docs]</a>
<span class="k">def</span> <span class="nf">subsequent_mask</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create a mask to hide subsequent positions in a sequence.</span>

<span class="sd">    Args:</span>
<span class="sd">        size: The length of the sequence.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tensor of shape (1, size, size) with True values in the upper triangular part.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">attn_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="n">subsequent_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">attn_shape</span><span class="p">),</span> <span class="n">diagonal</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">type</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">uint8</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">subsequent_mask</span> <span class="o">==</span> <span class="mi">0</span></div>



<div class="viewcode-block" id="run_epoch">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.run_epoch">[docs]</a>
<span class="k">def</span> <span class="nf">run_epoch</span><span class="p">(</span>
    <span class="n">data_iter</span><span class="p">,</span>
    <span class="n">model</span><span class="p">,</span>
    <span class="n">wiener_fn</span><span class="p">,</span>
    <span class="n">classic_loss</span><span class="p">,</span>
    <span class="n">optimizer</span><span class="p">,</span>
    <span class="n">scheduler</span><span class="p">,</span>
    <span class="n">accelerator</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span>
    <span class="n">loss_weight</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">accum_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">train_state</span><span class="o">=</span><span class="n">TrainState</span><span class="p">(),</span>
    <span class="n">max_batches</span><span class="o">=</span><span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">),</span>
    <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">awl</span><span class="o">=</span><span class="kc">None</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Train or evaluate the model for a single epoch.</span>

<span class="sd">    Args:</span>
<span class="sd">        data_iter: DataLoader providing batches of data.</span>
<span class="sd">        model: The model being trained or evaluated.</span>
<span class="sd">        wiener_fn: Function to compute the Wiener loss (if applicable).</span>
<span class="sd">        classic_loss: Function to compute the standard loss (e.g., cross-entropy).</span>
<span class="sd">        optimizer: Optimizer used for training.</span>
<span class="sd">        scheduler: Learning rate scheduler.</span>
<span class="sd">        accelerator: Distributed training utility (e.g., from Hugging Face&#39;s Accelerate).</span>
<span class="sd">        mode: Mode of operation, either &quot;train&quot; or &quot;eval&quot; (default: &quot;train&quot;).</span>
<span class="sd">        loss_weight: Weighting factor for the loss function (default: 1).</span>
<span class="sd">        accum_iter: Number of steps for gradient accumulation (default: 1).</span>
<span class="sd">        train_state: Object tracking training state (default: TrainState()).</span>
<span class="sd">        max_batches: Maximum number of batches to process (default: inf).</span>
<span class="sd">        gamma: Regularization parameter for the Wiener loss (default: 0.1).</span>
<span class="sd">        awl: Automatic weighting of losses (if applicable).</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple containing:</span>
<span class="sd">            - avg_loss: Average combined loss over the epoch.</span>
<span class="sd">            - avg_wiener: Average Wiener loss over the epoch.</span>
<span class="sd">            - avg_kldiv: Average Kullback-Leibler divergence loss over the epoch.</span>
<span class="sd">            - train_state: Updated training state after the epoch.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_wiener</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total_kldiv</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">n_accum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">batch_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">context_manager</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;eval&quot;</span> <span class="k">else</span> <span class="n">nullcontext</span><span class="p">()</span>
    <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">context_manager</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data_iter</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">max_batches</span><span class="p">:</span>
                <span class="k">break</span>
            
            <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span>
                <span class="n">batch</span><span class="o">.</span><span class="n">src</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">tgt</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">tgt_mask</span>
            <span class="p">)</span>
            <span class="k">if</span> <span class="n">wiener_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">true</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">module</span><span class="o">.</span><span class="n">tgt_embed</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">tgt_y</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">true</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">tgt_embed</span><span class="p">(</span><span class="n">batch</span><span class="o">.</span><span class="n">tgt_y</span><span class="p">)</span>
                <span class="n">wiener</span> <span class="o">=</span> <span class="n">wiener_fn</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">true</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">512</span><span class="p">),</span> <span class="n">gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">wiener</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">_</span><span class="p">,</span> <span class="n">kldiv_node</span> <span class="o">=</span> <span class="n">classic_loss</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">tgt_y</span><span class="p">,</span> <span class="n">batch</span><span class="o">.</span><span class="n">ntokens</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">awl</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">kldiv_node</span> <span class="o">=</span> <span class="n">loss_weight</span><span class="o">*</span><span class="n">kldiv_node</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">wiener</span> <span class="o">+</span> <span class="n">kldiv_node</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span><span class="p">,</span> <span class="n">losses</span> <span class="o">=</span> <span class="n">awl</span><span class="p">(</span><span class="n">wiener</span><span class="p">,</span> <span class="n">kldiv_node</span><span class="p">)</span>
                <span class="n">wiener</span><span class="p">,</span> <span class="n">kldiv_node</span> <span class="o">=</span> <span class="n">losses</span>

            <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">or</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train+log&quot;</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">accelerator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">accelerator</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                <span class="n">train_state</span><span class="o">.</span><span class="n">step</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">train_state</span><span class="o">.</span><span class="n">samples</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">src</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">train_state</span><span class="o">.</span><span class="n">tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">ntokens</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">accum_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                    <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                    <span class="n">n_accum</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="n">train_state</span><span class="o">.</span><span class="n">accum_step</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">wiener_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">total_wiener</span> <span class="o">+=</span> <span class="n">wiener</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_kldiv</span> <span class="o">+=</span> <span class="n">kldiv_node</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">total_tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">ntokens</span>
            <span class="n">tokens</span> <span class="o">+=</span> <span class="n">batch</span><span class="o">.</span><span class="n">ntokens</span>
            <span class="n">batch_count</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">300</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="p">(</span><span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span> <span class="ow">or</span> <span class="n">mode</span> <span class="o">==</span> <span class="s2">&quot;train+log&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="n">accelerator</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">accelerator</span><span class="o">.</span><span class="n">is_main_process</span><span class="p">):</span>
                <span class="n">lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
                <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
                <span class="nb">print</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="s2">&quot;Epoch Step: </span><span class="si">%6d</span><span class="s2"> | Accumulation Step: </span><span class="si">%3d</span><span class="s2"> | Combined Loss: </span><span class="si">%6.5f</span><span class="s2"> | Wiener Loss: </span><span class="si">%6.5f</span><span class="s2"> | KLDiv Loss: </span><span class="si">%6.5f</span><span class="s2">&quot;</span>
                        <span class="o">+</span> <span class="s2">&quot;| Tokens / Sec: </span><span class="si">%7.1f</span><span class="s2"> | Learning Rate: </span><span class="si">%6.1e</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="o">%</span> <span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">n_accum</span><span class="p">,</span>  <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">wiener</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="k">if</span> <span class="n">wiener_fn</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span> <span class="n">kldiv_node</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">tokens</span> <span class="o">/</span> <span class="n">elapsed</span><span class="p">,</span> <span class="n">lr</span><span class="p">)</span>
                <span class="p">)</span>
                <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
                <span class="n">tokens</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="k">del</span> <span class="n">loss</span>

    <span class="n">avg_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">batch_count</span> <span class="k">if</span> <span class="n">batch_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">avg_wiener</span> <span class="o">=</span> <span class="n">total_wiener</span> <span class="o">/</span> <span class="n">batch_count</span> <span class="k">if</span> <span class="n">batch_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="n">avg_kldiv</span> <span class="o">=</span> <span class="n">total_kldiv</span> <span class="o">/</span> <span class="n">batch_count</span> <span class="k">if</span> <span class="n">batch_count</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="k">return</span> <span class="n">avg_loss</span><span class="p">,</span> <span class="n">avg_wiener</span><span class="p">,</span> <span class="n">avg_kldiv</span><span class="p">,</span> <span class="n">train_state</span></div>



<div class="viewcode-block" id="rate">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.rate">[docs]</a>
<span class="k">def</span> <span class="nf">rate</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">model_size</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">warmup</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the learning rate according to the warmup strategy.</span>

<span class="sd">    Args:</span>
<span class="sd">        step: Current step number.</span>
<span class="sd">        model_size: Dimensionality of the model.</span>
<span class="sd">        factor: Scaling factor for the learning rate.</span>
<span class="sd">        warmup: Number of warmup steps.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Learning rate value for the current step.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">step</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">factor</span> <span class="o">*</span> <span class="p">(</span>
        <span class="n">model_size</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="nb">min</span><span class="p">(</span><span class="n">step</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">step</span> <span class="o">*</span> <span class="n">warmup</span> <span class="o">**</span> <span class="p">(</span><span class="o">-</span><span class="mf">1.5</span><span class="p">))</span>
    <span class="p">)</span></div>



<div class="viewcode-block" id="pad">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.pad">[docs]</a>
<span class="k">def</span> <span class="nf">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pad a tensor with a specified value.</span>

<span class="sd">    Args:</span>
<span class="sd">        tensor: The tensor to be padded.</span>
<span class="sd">        pad: A tuple specifying the padding to be applied to each dimension.</span>
<span class="sd">        value: The value to use for padding.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Padded tensor.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">pad</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">value</span><span class="p">)</span></div>



<div class="viewcode-block" id="tokenize">
<a class="viewcode-back" href="../../../wiener_transformer.html#wiener_transformer.utils.helpers.tokenize">[docs]</a>
<span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">text</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenize a given text using a specified tokenizer.</span>

<span class="sd">    Args:</span>
<span class="sd">        text: The text to be tokenized.</span>
<span class="sd">        tokenizer: The tokenizer to be used for tokenization.</span>

<span class="sd">    Returns:</span>
<span class="sd">        List of tokens.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tok</span><span class="o">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">tok</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">)]</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../index.html">Wiener Transformer</a></h1>









<search id="searchbox" style="display: none" role="search">
    <div class="searchformwrapper">
    <form class="search" action="../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false" placeholder="Search"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script><h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../wiener_transformer.html">Wiener Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../wiener_transformer.html#utilities">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../wiener_attention.html">Wiener Attention</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../index.html">Documentation overview</a><ul>
  <li><a href="../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2024, Andrei Danila.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 8.0.2</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 1.0.0</a>
      
    </div>

    

    
  </body>
</html>